---
layout: post
title: "Most users cannot identify AI bias, even in training data"
date: 2025-10-19 06:35:17 +0000
categories: Artificial Intelligence
---

### [Most users cannot identify AI bias, even in training data](https://www.psu.edu/news/bellisario-college-communications/story/most-users-cannot-identify-ai-bias-even-training-data)

> When recognizing faces and emotions, artificial intelligence (AI) can be biased, like classifying white people as happier than people from other racial backgrounds. This happens because the data used to train the AI contained a disproportionate number of happy white faces, leading it to correlate race with emotional expression. In a recent study, published in Media Psychology, researchers asked users to assess such skewed training data, but most users didn’t notice the bias — unless they were in the negatively portrayed group.
![Preview Image](https://psu-gatsby-files-prod.s3.amazonaws.com/s3fs-public/styles/16_9_1000w/public/2025/10/aibias_research_bellisariocollege.jpg?h=707772c7&itok=I6Y0QM52)

